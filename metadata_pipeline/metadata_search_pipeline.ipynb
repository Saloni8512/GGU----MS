{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to pip install tika\n",
    "from tika import parser\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Metadata Term Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return true if our current value is NaN\n",
    "\n",
    "def isNan(a):\n",
    "    return a != a\n",
    "\n",
    "#generate dictionary \n",
    "#key is metadata field\n",
    "#value is a list of term1, term2, term3\n",
    "# we use this to match metadata fields to found terms in our sentence output document\n",
    "\n",
    "def metadata_term_library(df_metadata):\n",
    "    \n",
    "    dic_metadata_terms = {}\n",
    "    dic_metadata_original = {}\n",
    "    dic_metadata_category = {}\n",
    "    dic_metadata_subcategory = {}\n",
    "    \n",
    "    for i,j in df_metadata.iterrows():\n",
    "        \n",
    "        dic_metadata_original[j['Metadata']] = [j['Metadata_Original']]\n",
    "        dic_metadata_category[j['Metadata']] = [j['Category']]\n",
    "        dic_metadata_subcategory[j['Metadata']] = [j['Sub-Category']]\n",
    "\n",
    "        dic_metadata_terms[j['Metadata']] = [j['Term1']]\n",
    "                \n",
    "        if not isNan(j['Term2']):\n",
    "            dic_metadata_terms[j['Metadata']].append(j['Term2'])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if not isNan(j['Term3']):\n",
    "            dic_metadata_terms[j['Metadata']].append(j['Term3'])\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return(dic_metadata_terms, dic_metadata_original, dic_metadata_category, dic_metadata_subcategory)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified data structure for Term search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.pipeline import EntityRuler \n",
    "\n",
    "def sent_segment(txt):\n",
    "    \"\"\" sentence tokenization\n",
    "\n",
    "    Parameters:\n",
    "    txt : tex to tokenize into sentences\n",
    "    Returns: list of sentences\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Load English tokenizer, tagger, parser, NER and word vectors\n",
    "    nlp = English() \n",
    "\n",
    "    # A simple pipeline component, to allow custom sentence boundary detection logic \n",
    "    # that doesnâ€™t require the dependency parse. It splits on punctuation by default\n",
    "    sbd = nlp.create_pipe('sentencizer')\n",
    "\n",
    "    # Add the component to the pipeline\n",
    "    nlp.add_pipe(sbd)\n",
    "\n",
    "    #nlp is used to create documents with linguistic annotations.\n",
    "    doc = nlp(txt)   \n",
    "\n",
    "    # create list of sentence tokens\n",
    "    sents_list = []\n",
    "    for sent in doc.sents:\n",
    "        sents_list.append(sent.text)\n",
    "\n",
    "    return sents_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synonym finder\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "from itertools import chain\n",
    "\n",
    "# #find synonyms based on the keyword and build into a dataframe\n",
    "def get_synonyms(term_dic):\n",
    "\n",
    "    #list of tuples containing (category, original term, synonym)\n",
    "    term_tuples = []\n",
    "\n",
    "    \n",
    "    ####Issues passing number into wordnet. \n",
    "    L = []\n",
    "    for key in term_dic:\n",
    "\n",
    "        syn = wordnet.synsets(str(term_dic[key][0]))\n",
    "\n",
    "            \n",
    "        syn_list = [term_dic[key][0]]\n",
    "\n",
    "        #flatten all lists by chain, remove duplicates by set\n",
    "        lemmas = list(set(chain.from_iterable([w.lemma_names() for w in syn])))\n",
    "\n",
    "        for i in lemmas[:3]:\n",
    "            syn_list.append(i)\n",
    "\n",
    "        syn_list = list(set(syn_list))\n",
    "\n",
    "        for syn in syn_list:\n",
    "            L.append((key, term_dic[key][0], syn))\n",
    "\n",
    "            \n",
    "    return (pd.DataFrame(L, columns=['Metadata_Field','Original_Term','Synonym_Term']))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dataframe containing Metadata field, original term1, and the synonym term1\n",
    "\n",
    "# df_term1 = get_synonyms(dic_meta_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search proper keyword in the list of sentences\n",
    "# if found, grab surrounding lines, combine, and add to 3rd dataframe\n",
    "\n",
    "#sentence_df contains list of sentence segment in each row\n",
    "#term_df contains the category, original term, and synonym term in each row\n",
    "# Want to search the synonym term in sentence rows. Then if match found, add all those 4 columns to new dataframe\n",
    "\n",
    "\n",
    "def search_term(sentence_df, term_df):\n",
    "    \n",
    "    category_column_names = ['Metadata_Field','Original_Keyword', 'Searched_Keyword', 'Sentence_Number','Text']\n",
    "    df_metadata = pd.DataFrame(columns = category_column_names)\n",
    "\n",
    "    array_metadata = df_metadata.values\n",
    "    \n",
    "    for i,j in sentence_df.iterrows():\n",
    "        for m,n in term_df.iterrows():\n",
    "            if str(n['Synonym_Term']) in j['Sentences'].lower():\n",
    "                ####### do the iteration, search the term and add to dataframe\n",
    "                \n",
    "                df_found = pd.DataFrame([(n['Metadata_Field'],n['Original_Term'], n['Synonym_Term'], i, j['Sentences'])])\n",
    "                \n",
    "                array_metadata = np.concatenate(\\\n",
    "                        (array_metadata, df_found.values), axis=0)\n",
    "\n",
    "    df_metadata = pd.DataFrame(array_metadata, columns = category_column_names)\n",
    "    \n",
    "    return df_metadata\n",
    "\n",
    "\n",
    "#currently adding things to an np.array continually. then at the end, add it to the data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create context. takes current line of text and associated index. \n",
    "# lokos at the sentence dataframe and grabs correct rows.\n",
    "# allows us to search multiple segments for each original term\n",
    "\n",
    "#pass the original sentence dataframe and current row of the metadata dataframe\n",
    "def create_context(sentence_df, metadata_df, idx):\n",
    "    \n",
    "    sentence_idx = metadata_df.iloc[idx]['Sentence_Number']\n",
    "    \n",
    "    try:\n",
    "        context = sentence_df.iloc[sentence_idx - 1]['Sentences'] + \\\n",
    "        sentence_df.iloc[sentence_idx]['Sentences'] + \\\n",
    "        sentence_df.iloc[sentence_idx + 1]['Sentences']\n",
    "    except:\n",
    "        \n",
    "        context = sentence_df.iloc[sentence_idx]['Sentences']\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uses a secondary library of terms\n",
    "# Keys in this library will match the 'original keyword' column in the metadata_df\n",
    "# Iterate through associated list of terms\n",
    "# If secondary term found, add it to new column\n",
    "# adds to an existing dataframe with enough columns so just need to generate list and add to new column\n",
    "\n",
    "#Need to add greater context to each line. grab sentence from sentence dataframe\n",
    "\n",
    "def search_secondary(sentence_df, metadata_df, term_dic):\n",
    "    \n",
    "    secondary_term_outer = []\n",
    "    secondary_syn_outer = []\n",
    "    secondary_context_outer = []\n",
    "    \n",
    "    for i,j in metadata_df.iterrows():\n",
    "        \n",
    "        context = create_context(sentence_df, metadata_df, i)\n",
    "        \n",
    "        secondary_term_inner = [] \n",
    "        secondary_syn_inner = []\n",
    "        secondary_context_inner = None\n",
    "        term1 = term_dic[j['Metadata_Field']]\n",
    "        \n",
    "    \n",
    "        if len(term1) > 1:\n",
    "\n",
    "            for k in range(1,len(term1)):\n",
    "\n",
    "                item = str(term1[k])\n",
    "\n",
    "                syn = wordnet.synsets(item)\n",
    "\n",
    "                syn_list = [item]\n",
    "\n",
    "                #flatten all lists by chain, remove duplicates by set\n",
    "                lemmas = list(set(chain.from_iterable([w.lemma_names() for w in syn])))                \n",
    "\n",
    "                for m in lemmas[:3]:\n",
    "                    syn_list.append(m)\n",
    "\n",
    "                syn_list = list(set(syn_list))\n",
    "\n",
    "                for syn in syn_list:\n",
    "\n",
    "                    if syn in context.lower() and secondary_context_inner == None:\n",
    "                        secondary_term_inner.append(item)\n",
    "                        secondary_syn_inner.append(syn)\n",
    "                        secondary_context_inner = context\n",
    "\n",
    "                    elif syn in context.lower():\n",
    "                        secondary_term_inner.append(item)\n",
    "                        secondary_syn_inner.append(syn)\n",
    "\n",
    "                    else:\n",
    "                        pass\n",
    "        else:\n",
    "            secondary_context_inner = context\n",
    "\n",
    "\n",
    "                                      \n",
    "        secondary_term_outer.append(secondary_term_inner)\n",
    "        secondary_syn_outer.append(secondary_syn_inner)\n",
    "        secondary_context_outer.append(secondary_context_inner)\n",
    "    \n",
    "    metadata_df['Secondary_Term'] = secondary_term_outer\n",
    "    metadata_df['Secondary_Synonym'] = secondary_syn_outer\n",
    "    metadata_df['Secondary_Context'] = secondary_context_outer\n",
    "    \n",
    "    return metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs metadata dictionary\n",
    "#sentence found keyword dataframe\n",
    "#iterate through sentence dataframe\n",
    "# look at the combined terminology list of original_keyword and seondary_term\n",
    "# see if metadata search temrs are contained in the list\n",
    "# if all terms are in the sentence term list, then add the associated metadata term to the row as possible match\n",
    "\n",
    "def combine_keyword_list(df_keyword):\n",
    "    \n",
    "    complete_term_list = []\n",
    "    \n",
    "    for i,j in df_keyword.iterrows():\n",
    "        secondary_term_tolist = eval(str(j['Secondary_Term']))\n",
    "        original_keyword_string = str(j['Original_Keyword'])\n",
    "        \n",
    "        #print(type(original_keyword_string))\n",
    "        \n",
    "        #print(secondary_term_tolist)\n",
    "        secondary_term_tolist.append(original_keyword_string)\n",
    "        complete_terms = secondary_term_tolist\n",
    "        \n",
    "        complete_term_list.append(complete_terms)\n",
    "        \n",
    "    df_keyword['Complete_Term_List'] = complete_term_list\n",
    "    \n",
    "    return df_keyword\n",
    "\n",
    "##test\n",
    "#combine_keyword_list(df_sentence_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check each row to see if metadata fields are in the keywords list\n",
    "# create new column in dataframe that shows all possible metadata matches\n",
    "\n",
    "def metadata_match(df_keyword, dic_metadata, dic_original, dic_cat, dic_subcat):\n",
    "    \n",
    "    metadata_matches_outer = []\n",
    "    metadata_original_match_outer = []\n",
    "    metadata_category_outer = []\n",
    "    metadata_subcategory_outer = []\n",
    "    \n",
    "    \n",
    "    for i,j in df_keyword.iterrows():\n",
    "        \n",
    "        metadata_matches_inner = []\n",
    "        original_match_inner = []\n",
    "        category_match_inner = []\n",
    "        subcategory_match_inner = []\n",
    "\n",
    "                   \n",
    "        term_list = j['Complete_Term_List']\n",
    "        \n",
    "        for key in dic_metadata:\n",
    "            \n",
    "            if all(elem in term_list for elem in dic_metadata[key]):\n",
    "                metadata_matches_inner.append(key)\n",
    "                original_match_inner.append(dic_original[key][0])\n",
    "                category_match_inner.append(dic_cat[key][0])\n",
    "                subcategory_match_inner.append(dic_subcat[key][0])\n",
    "                                   \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        metadata_matches_outer.append(metadata_matches_inner)\n",
    "        metadata_original_match_outer.append(list(set(original_match_inner)))\n",
    "        metadata_category_outer.append(list(set(category_match_inner)))\n",
    "        metadata_subcategory_outer.append(list(set(subcategory_match_inner)))\n",
    "    \n",
    "    df_keyword['Metadata_Matches'] = metadata_matches_outer\n",
    "    df_keyword['Metadata_Original'] = metadata_original_match_outer\n",
    "    df_keyword['Metadata_Category'] = metadata_category_outer\n",
    "    df_keyword['Metadata_Subcategory'] = metadata_subcategory_outer\n",
    "    \n",
    "    #remove lines with know metadata field match\n",
    "    df_keyword = df_keyword[df_keyword['Metadata_Matches'].map(lambda d: len(d)) > 0]\n",
    "    \n",
    "    #print(df_keyword['Metadata_Matches'][1])\n",
    "    return df_keyword\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "Start with input dictionary containing category and keyword.  \n",
    "Use keyword to search synonyms. Create a tuple of (category, keyword, synonym) and append those to a list.  \n",
    "Iterate through list and search for synonym in text of df_sentence.  \n",
    "Create a dataframe of ['category', 'keyword', 'synonym', 'text']  \n",
    "\n",
    "\n",
    "Best algorithm for this? Right now looking at O(n_squared)\n",
    "    - (number of terms) * (number of sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-16 08:36:15,822 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n"
     ]
    }
   ],
   "source": [
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "\n",
    "#create contract list\n",
    "# contract_path = 'C:\\\\Users\\\\Hello\\\\Desktop\\\\metric_stream\\\\v0.022\\\\metadata_pipeline\\\\data\\\\'\n",
    "#contract_names = listdir(contract_path)\n",
    "#remove .pdf Use for file name in csv export at end\n",
    "\n",
    "# contract_files = [contract_path + f for f in listdir(contract_path) if isfile(join(contract_path, f))]\n",
    "\n",
    "#can loop through list for contract files\n",
    "# parsed_contract = parser.from_file(contract_files[0])\n",
    "# pdf_doc = parsed_contract['content']\n",
    "\n",
    "\n",
    "#print(contract_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "#put your contract path + file name in contract_files\n",
    "\n",
    "contract_files = 'C:\\\\Users\\\\Hello\\\\Desktop\\\\metric_stream\\\\v0.022\\\\metadata_pipeline\\\\data\\\\'\n",
    "parsed_contract = parser.from_file(contract_files)\n",
    "pdf_doc = parsed_contract['content']\n",
    "\n",
    "\n",
    "#print(contract_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate sentence list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dic_meta_term is list of terminology associated with metadata field\n",
    "#dic_meta_category is mapping of metadata field to a metadata category (original metadata field provided to us)\n",
    "\n",
    "metadata_file = pd.read_excel('C:\\\\Users\\\\Hello\\\\Desktop\\\\metric_stream\\\\v0.022\\\\metadata_pipeline\\\\metadata_documents\\\\metadata_library.xlsx')\n",
    "dic_meta_term, dic_meta_original, dic_meta_cat, dic_meta_subcat = metadata_term_library(metadata_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove newlines\n",
    "#Remove sentence that are too short (usually 1 or 2 symbols)\n",
    "\n",
    "sentence_list = sent_segment(pdf_doc)\n",
    "sentence_list_clean = []\n",
    "\n",
    "for i in range(0,len(sentence_list)):\n",
    "    remove_newline = sentence_list[i].replace('\\n', '')\n",
    "    if len(sentence_list[i]) > 4:\n",
    "        sentence_list_clean.append(remove_newline)\n",
    "    else: pass\n",
    "    \n",
    "#Write sentence list dataframe to file\n",
    "\n",
    "dic_sentence = {'Sentences' : sentence_list_clean} \n",
    "df_sentence = pd.DataFrame.from_dict(dic_sentence)\n",
    "\n",
    "#df_sentence.head()\n",
    "#df_sentence.to_csv('sentences0615.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match sentences with Metadata terminology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe containing Metadata field, original term1, and the synonym term1\n",
    "df_words = get_synonyms(dic_meta_term)\n",
    "\n",
    "\n",
    "df_metadata0 = search_term(df_sentence, df_words)\n",
    "\n",
    "\n",
    "df_metadata_2 = search_secondary(df_sentence, df_metadata0, dic_meta_term)\n",
    "\n",
    "#df_metadata_2.to_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match found metadata terms to original metadata field and category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_terms = combine_keyword_list(df_metadata_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined_terms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadata_Field</th>\n",
       "      <th>Original_Keyword</th>\n",
       "      <th>Searched_Keyword</th>\n",
       "      <th>Sentence_Number</th>\n",
       "      <th>Text</th>\n",
       "      <th>Secondary_Term</th>\n",
       "      <th>Secondary_Synonym</th>\n",
       "      <th>Secondary_Context</th>\n",
       "      <th>Complete_Term_List</th>\n",
       "      <th>Metadata_Matches</th>\n",
       "      <th>Metadata_Original</th>\n",
       "      <th>Metadata_Category</th>\n",
       "      <th>Metadata_Subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>ic</td>\n",
       "      <td>0</td>\n",
       "      <td>Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>99.8</td>\n",
       "      <td>99</td>\n",
       "      <td>ic</td>\n",
       "      <td>0</td>\n",
       "      <td>Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>99.9</td>\n",
       "      <td>99</td>\n",
       "      <td>ic</td>\n",
       "      <td>0</td>\n",
       "      <td>Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>99.99</td>\n",
       "      <td>99</td>\n",
       "      <td>ic</td>\n",
       "      <td>0</td>\n",
       "      <td>Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Churn Effective Date</td>\n",
       "      <td>date</td>\n",
       "      <td>date</td>\n",
       "      <td>0</td>\n",
       "      <td>Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...</td>\n",
       "      <td>[effective]</td>\n",
       "      <td>[effective]</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "      <td>[effective, date]</td>\n",
       "      <td>[Effective Date]</td>\n",
       "      <td>[Effective Date]</td>\n",
       "      <td>[Time]</td>\n",
       "      <td>[Contact]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Metadata_Field Original_Keyword Searched_Keyword Sentence_Number  \\\n",
       "0                    99               99               ic               0   \n",
       "1                  99.8               99               ic               0   \n",
       "2                  99.9               99               ic               0   \n",
       "3                 99.99               99               ic               0   \n",
       "4  Churn Effective Date             date             date               0   \n",
       "\n",
       "                                                Text Secondary_Term  \\\n",
       "0  Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...             []   \n",
       "1  Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...             []   \n",
       "2  Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...             []   \n",
       "3  Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...             []   \n",
       "4  Page 1 of 17  SOFTWARE LICENSE AGREEMENT  This...    [effective]   \n",
       "\n",
       "  Secondary_Synonym                                  Secondary_Context  \\\n",
       "0                []    MetrieStream, Inc.   By  (Print Name) Title ...   \n",
       "1                []    MetrieStream, Inc.   By  (Print Name) Title ...   \n",
       "2                []    MetrieStream, Inc.   By  (Print Name) Title ...   \n",
       "3                []    MetrieStream, Inc.   By  (Print Name) Title ...   \n",
       "4       [effective]    MetrieStream, Inc.   By  (Print Name) Title ...   \n",
       "\n",
       "  Complete_Term_List  Metadata_Matches Metadata_Original Metadata_Category  \\\n",
       "0               [99]              [99]              [99]           [Value]   \n",
       "1               [99]              [99]              [99]           [Value]   \n",
       "2               [99]              [99]              [99]           [Value]   \n",
       "3               [99]              [99]              [99]           [Value]   \n",
       "4  [effective, date]  [Effective Date]  [Effective Date]            [Time]   \n",
       "\n",
       "  Metadata_Subcategory  \n",
       "0                [nan]  \n",
       "1                [nan]  \n",
       "2                [nan]  \n",
       "3                [nan]  \n",
       "4            [Contact]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MAtch score (maybe)-> number of fields picked up (minimum 50% or something)\n",
    "\n",
    "df_metadata_match = metadata_match(df_combined_terms, dic_meta_term, dic_meta_original, dic_meta_cat, dic_meta_subcat)\n",
    "df_metadata_match.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata_match.to_csv('test_metadata_match0615.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplify Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadata_Category</th>\n",
       "      <th>Metadata_Original</th>\n",
       "      <th>Metadata_Field</th>\n",
       "      <th>Secondary_Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>99</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>99.8</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>99.9</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>[Value]</td>\n",
       "      <td>[99]</td>\n",
       "      <td>99.99</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[Time]</td>\n",
       "      <td>[Effective Date]</td>\n",
       "      <td>Churn Effective Date</td>\n",
       "      <td>MetrieStream, Inc.   By  (Print Name) Title ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metadata_Category Metadata_Original        Metadata_Field  \\\n",
       "0           [Value]              [99]                    99   \n",
       "1           [Value]              [99]                  99.8   \n",
       "2           [Value]              [99]                  99.9   \n",
       "3           [Value]              [99]                 99.99   \n",
       "4            [Time]  [Effective Date]  Churn Effective Date   \n",
       "\n",
       "                                   Secondary_Context  \n",
       "0    MetrieStream, Inc.   By  (Print Name) Title ...  \n",
       "1    MetrieStream, Inc.   By  (Print Name) Title ...  \n",
       "2    MetrieStream, Inc.   By  (Print Name) Title ...  \n",
       "3    MetrieStream, Inc.   By  (Print Name) Title ...  \n",
       "4    MetrieStream, Inc.   By  (Print Name) Title ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_metadata_simplified = df_metadata_match[['Metadata_Category','Metadata_Original','Metadata_Field','Secondary_Context']]\n",
    "# df_metadata_simplified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# #df_metadata_simplified.to_csv('test2.csv')\n",
    "# df_metadata_simplified = pd.read_csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metadata_Category</th>\n",
       "      <th>Metadata_Original</th>\n",
       "      <th>Metadata_Field</th>\n",
       "      <th>Secondary_Context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>['Agreement']</td>\n",
       "      <td>['Agreement Type']</td>\n",
       "      <td>Amendment</td>\n",
       "      <td>1.3 Change in Scope.If Bank requests an expan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>['Agreement']</td>\n",
       "      <td>['Agreement Type']</td>\n",
       "      <td>Amendment</td>\n",
       "      <td>If Company requests a change in the scope of S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>['Agreement']</td>\n",
       "      <td>['Agreement Type']</td>\n",
       "      <td>Amendment</td>\n",
       "      <td>Company agrees to use reasonable efforts to id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>['Agreement']</td>\n",
       "      <td>['Agreement Type']</td>\n",
       "      <td>Amendment</td>\n",
       "      <td>For purposes of understanding, these Deliverab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>['Agreement']</td>\n",
       "      <td>['backup']</td>\n",
       "      <td>backup</td>\n",
       "      <td>Licensee shall not make or permit others to ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metadata_Category   Metadata_Original Metadata_Field  \\\n",
       "0     ['Agreement']  ['Agreement Type']      Amendment   \n",
       "1     ['Agreement']  ['Agreement Type']      Amendment   \n",
       "2     ['Agreement']  ['Agreement Type']      Amendment   \n",
       "3     ['Agreement']  ['Agreement Type']      Amendment   \n",
       "4     ['Agreement']          ['backup']         backup   \n",
       "\n",
       "                                   Secondary_Context  \n",
       "0   1.3 Change in Scope.If Bank requests an expan...  \n",
       "1  If Company requests a change in the scope of S...  \n",
       "2  Company agrees to use reasonable efforts to id...  \n",
       "3  For purposes of understanding, these Deliverab...  \n",
       "4  Licensee shall not make or permit others to ma...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_metadata_simplified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strong Match\n",
    "look for exact match of metadata term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #look for exact term in context\n",
    "\n",
    "# def strong_match(df_metadata):\n",
    "     \n",
    "#     for i,j in df_metadata.iterrows():\n",
    "#         if str(j['Metadata_Field']).lower() in str(j['Secondary_Context']).lower():\n",
    "#             pass\n",
    "#         else:\n",
    "#             df_metadata.drop(i, inplace=True)\n",
    "            \n",
    "#     return df_metadata\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_strongmatch = strong_match(df_metadata_simplified)\n",
    "# df_strongmatch.to_csv('test3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove duplicates using text Cosine distance\n",
    "--- to be implemented later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#cosine.distance of 0 means no difference in text\n",
    "#therefore our threshold will be cosine.distance > value\n",
    "#cosine.distance(text1,text2)\n",
    "\n",
    "from textdistance import cosine\n",
    "\n",
    "def remove_duplicate_text(df_metadata):\n",
    "    \n",
    "    #unique_metadata_field = list(df_metadata.Metadata_Field.unique())\n",
    "    unique_metadata_field = ['breach']\n",
    "    \n",
    "    for mdf in unique_metadata_field:\n",
    "        \n",
    "        df_single_term = df_metadata[df_metadata.Metadata_Field == mdf]\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    return df_single_term\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
